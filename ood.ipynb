{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6de6413-ee03-4ace-84ee-a767a6a7f113",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load the dataset\n",
    "with open(\"clinc150_uci/data_full.json\", \"r\") as file:\n",
    "    data = json.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "79e7f929-861a-4a2e-8e3c-9acdfe8c930a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['damaged_card', 'min_payment', 'w2', 'definition', 'redeem_rewards']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_intents = list(set(train_labels)) \n",
    "unique_intents[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20662a82-da0b-4d9c-a2eb-2a11f02e7abc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 3000, 4500, 100, 100, 1000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting data\n",
    "train_data = data['train']\n",
    "val_data = data['val']\n",
    "test_data = data['test']\n",
    "\n",
    "oos_train_data = data['oos_train']\n",
    "oos_val_data = data['oos_val']\n",
    "oos_test_data = data['oos_test']\n",
    "\n",
    "# Get sentences and labels\n",
    "train_sentences = [item[0] for item in train_data]\n",
    "train_labels = [item[1] for item in train_data]\n",
    "\n",
    "val_sentences = [item[0] for item in val_data]\n",
    "val_labels = [item[1] for item in val_data]\n",
    "\n",
    "test_sentences = [item[0] for item in test_data]\n",
    "test_labels = [item[1] for item in test_data]\n",
    "\n",
    "oos_train_sentences = [item[0] for item in oos_train_data]\n",
    "oos_val_sentences = [item[0] for item in oos_val_data]\n",
    "oos_test_sentences = [item[0] for item in oos_test_data]\n",
    "\n",
    "# Check the number of samples in each subset\n",
    "len(train_sentences), len(val_sentences), len(test_sentences), len(oos_train_sentences), len(oos_val_sentences), len(oos_test_sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c43b3818-f7a2-4ed8-9c18-55a5016c71ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d2a7995-d5be-40ac-a692-241cd27d5090",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Initialize tokenizer and model\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "model = RobertaModel.from_pretrained('roberta-base')\n",
    "if torch.cuda.is_available():\n",
    "    model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d739581-6f92-4cf2-bc42-07e33ceb84bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(sentences):\n",
    "    inputs = tokenizer(sentences, return_tensors=\"pt\", padding=True, truncation=True, max_length=256)\n",
    "    \n",
    "    # Move inputs to GPU if available\n",
    "    if torch.cuda.is_available():\n",
    "        for key in inputs:\n",
    "            inputs[key] = inputs[key].to('cuda')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Move embeddings back to CPU if they were on GPU\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "    if torch.cuda.is_available():\n",
    "        embeddings = embeddings.cpu()\n",
    "    \n",
    "    return embeddings.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06a95d9f-0c13-4045-bffc-8dcdd42b89d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embeddings = get_embeddings(train_sentences)\n",
    "val_embeddings = get_embeddings(val_sentences)\n",
    "test_embeddings = get_embeddings(test_sentences)\n",
    "oos_train_embeddings = get_embeddings(oos_train_sentences)\n",
    "oos_val_embeddings = get_embeddings(oos_val_sentences)\n",
    "oos_test_embeddings = get_embeddings(oos_test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74c2a412-0120-4122-b695-ca60344f3b53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 768)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e980c7a9-4964-43c8-b4e4-0d4b0c65a550",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da4072ea-8c27-4b02-ae98-391c7b585c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "intent_means = {}\n",
    "\n",
    "for intent in unique_intents:\n",
    "    indices = [i for i, label in enumerate(train_labels) if label == intent]\n",
    "    intent_embeddings = train_embeddings[indices]\n",
    "    intent_mean = np.mean(intent_embeddings, axis=0)\n",
    "    intent_means[intent] = intent_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e1089b85-3d6d-44b5-9fc2-6b238579d432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(intent_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7a621819-84a4-48a5-8dab-f06741cc86b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intent_means[\"damaged_card\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "016e0919-3dc2-4ca7-9c11-012e4d9d0089",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2e022d34-99a6-4e7a-bb76-154381f8b4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "covariance = np.cov(train_embeddings, rowvar=False)\n",
    "cov_inverse = inv(covariance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9ca6f231-5b41-40b0-a13a-19cd9abae377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mahalanobis_distance(x, mean, cov_inverse):\n",
    "    delta = x - mean\n",
    "    return np.sqrt(np.dot(np.dot(delta, cov_inverse), delta.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d0032f82-2218-43ab-b87c-a7c9df1493ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'roc_curve' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m labels \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(in_domain_distances) \u001b[38;5;241m+\u001b[39m [\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(ood_distances)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Plot ROC curve and find optimal threshold\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m fpr, tpr, thresholds \u001b[38;5;241m=\u001b[39m \u001b[43mroc_curve\u001b[49m(labels, all_distances)\n\u001b[1;32m     16\u001b[0m j_statistic \u001b[38;5;241m=\u001b[39m tpr \u001b[38;5;241m-\u001b[39m fpr\n\u001b[1;32m     17\u001b[0m optimal_idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(j_statistic)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'roc_curve' is not defined"
     ]
    }
   ],
   "source": [
    "# Function to get the minimum Mahalanobis distance to any intent for a given sample\n",
    "def min_mahalanobis_for_sample(sample, intent_means, cov_inverse):\n",
    "    distances = [mahalanobis_distance(sample, mean, cov_inverse) for mean in intent_means.values()]\n",
    "    return min(distances)\n",
    "\n",
    "# Compute minimum Mahalanobis distances for in-domain and OOD samples\n",
    "in_domain_distances = [min_mahalanobis_for_sample(sample, intent_means, cov_inverse) for sample in train_embeddings]\n",
    "ood_distances = [min_mahalanobis_for_sample(sample, intent_means, cov_inverse) for sample in oos_train_embeddings]\n",
    "\n",
    "# Combine distances and labels for ROC curve analysis\n",
    "all_distances = in_domain_distances + ood_distances\n",
    "labels = [0] * len(in_domain_distances) + [1] * len(ood_distances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "449b8d06-fd6b-46d4-b55f-7939ad63fb1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.45210727736942"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot ROC curve and find optimal threshold\n",
    "fpr, tpr, thresholds = roc_curve(labels, all_distances)\n",
    "j_statistic = tpr - fpr\n",
    "optimal_idx = np.argmax(j_statistic)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "\n",
    "optimal_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "815eedc1-171c-4f52-b2aa-a7a1137e3dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to classify a sample based on the minimum Mahalanobis distance and threshold\n",
    "def classify_sample(sample, intent_means, cov_inverse, threshold):\n",
    "    min_distance = min_mahalanobis_for_sample(sample, intent_means, cov_inverse)\n",
    "    return \"OOD\" if min_distance > threshold else \"In-domain\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "425ea622-da38-47c8-ba4f-cc3cda71013c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify samples in test_embeddings and oos_test_embeddings\n",
    "test_classifications = [classify_sample(sample, intent_means, cov_inverse, optimal_threshold) for sample in test_embeddings]\n",
    "oos_test_classifications = [classify_sample(sample, intent_means, cov_inverse, optimal_threshold) for sample in oos_test_embeddings]\n",
    "\n",
    "# Construct true labels and predictions\n",
    "true_labels = [\"In-domain\"] * len(test_embeddings) + [\"OOD\"] * len(oos_test_embeddings)\n",
    "predicted_labels = test_classifications + oos_test_classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d5dc4053-c99d-4b2b-9238-17235acec795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   In-domain       0.92      0.67      0.77      4500\n",
      "         OOD       0.33      0.73      0.45      1000\n",
      "\n",
      "    accuracy                           0.68      5500\n",
      "   macro avg       0.62      0.70      0.61      5500\n",
      "weighted avg       0.81      0.68      0.71      5500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(true_labels, predicted_labels, target_names=[\"In-domain\", \"OOD\"])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7fcdebf2-c8fd-4780-9cb6-39073c0d1e55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30051144657351053"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "# Compute minimum Mahalanobis distances for samples in test_embeddings and oos_test_embeddings\n",
    "test_scores = [min_mahalanobis_for_sample(sample, intent_means, cov_inverse) for sample in test_embeddings]\n",
    "oos_test_scores = [min_mahalanobis_for_sample(sample, intent_means, cov_inverse) for sample in oos_test_embeddings]\n",
    "\n",
    "# True binary labels: 0 for in-domain and 1 for OOD\n",
    "y_true = [0] * len(test_scores) + [1] * len(oos_test_scores)\n",
    "\n",
    "# Combine the scores\n",
    "y_scores = test_scores + oos_test_scores\n",
    "\n",
    "# Compute AUPR\n",
    "aupr = average_precision_score(y_true, y_scores)\n",
    "aupr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "55bd2f12-0a08-4b17-b98c-ef502fbe3a9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5986666666666667"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
    "\n",
    "# Find the FPR where the TPR is closest to 0.95\n",
    "idx = np.where(tpr >= 0.95)[0][0]\n",
    "fpr_95 = fpr[idx]\n",
    "\n",
    "fpr_95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bce1f4-7b9e-4692-8039-630bb3b90955",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
